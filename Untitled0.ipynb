{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1MHS__aKzMvMGg3RdZT4CGvLx9udBgQ7e",
      "authorship_tag": "ABX9TyMq6/tJ1bvlNc5ehN3y/9Hr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SANGSEOSEO/BayesianOptimization/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle API Key and Install Kaggle API"
      ],
      "metadata": {
        "id": "KRerw2QEtOD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am2K2U2R_2WA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041cefac-0d55-4d6c-f2c4-1fdaa2da0780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle  # 캐글 라이브러리 설치\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'  # API 키 저장 경로 설정\n",
        "!chmod 600 /content/kaggle.json  # 보안 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BayesOptimization install"
      ],
      "metadata": {
        "id": "4AhQxlYlLnCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNGJMsuvLrcD",
        "outputId": "72cba7f6-876d-49d3-848d-c02031bc7200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-2.0.3-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.6 (from bayesian-optimization)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.6.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.6.0)\n",
            "Downloading bayesian_optimization-2.0.3-py3-none-any.whl (31 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-2.0.3 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Safe Driver Prediction Performance Boosting II : XGBoost Model"
      ],
      "metadata": {
        "id": "ptgmVCvgwICj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> XGBoost is a high-performance tree-based boosting algorithm that uses decision trees in series, as opposed to random forests which are place in parallel.\n",
        "\n"
      ],
      "metadata": {
        "id": "V0yE0A9Hwk2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Safer Driver Prediction Link](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)\n",
        "\n",
        "[Modeling code reference](https://www.kaggle.com/xiaozhouwang/2nd-place-lightgbm-solution)"
      ],
      "metadata": {
        "id": "Y8NyIE75wzsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Wuk7mrOrA6P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Kaggle/input/porto-seguro-safe-driver-prediction/'\n",
        "train = pd.read_csv(data_path + 'train.csv' , index_col='id')\n",
        "test  = pd.read_csv(data_path + 'test.csv',   index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')\n"
      ],
      "metadata": {
        "id": "VDYJjSOsuJBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "zSlHGzWqA6qO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Concatenaetion"
      ],
      "metadata": {
        "id": "6xlqES2mxr_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([train, test], ignore_index = True)\n",
        "all_data = all_data.drop('target', axis = 1) # Drop target feature\n",
        "all_features = all_data.columns   # all_features"
      ],
      "metadata": {
        "id": "RyuReUJexwsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OneHotEncoding  for nominal features"
      ],
      "metadata": {
        "id": "-B81a5K5yRB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# nominal features\n",
        "cat_features = [feature for feature in all_features if 'cat' in feature]\n",
        "cat_features\n",
        "\n",
        "onehot_encoder = OneHotEncoder()\n",
        "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])"
      ],
      "metadata": {
        "id": "oijV7-IbyNym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_cat_matrix   # stored elements and shape (1488028, 184)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SakFGGcyLOU",
        "outputId": "330653f0-217b-434a-f4ec-4c5405d2b525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 20832392 stored elements and shape (1488028, 184)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add a drived featue"
      ],
      "metadata": {
        "id": "SrsB7e0h0_UM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   num_missing\n",
        "Ther area many diffrent features that can be used to determine whether a driver is eligible for a claim.\n",
        "If we know the number of missing values or unique value count for each feature, we can make inferences about the predictability of being a safe driver.\n",
        "\n"
      ],
      "metadata": {
        "id": "kVUX4L_O1DYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data['num_missing'] = (all_data == -1).sum(axis = 1)"
      ],
      "metadata": {
        "id": "tpM3zDhR1Gsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### remaining featues"
      ],
      "metadata": {
        "id": "T52NclC62xaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclusing catxxx and calcxxx featues\n",
        "remaining_features = [feature for feature in all_features if ('cat' not in feature and 'calc' not in feature)]\n",
        "# remaining_features\n",
        "remaining_features.append('num_missing')"
      ],
      "metadata": {
        "id": "VQz52Yy221X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   indxxxx featues\n",
        "\n"
      ],
      "metadata": {
        "id": "4vp9Zubu3d8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind_features = [feature for feature in all_features if 'ind' in feature]\n",
        "\n",
        "is_first_feature = True\n",
        "for ind_feature in ind_features:\n",
        "  if is_first_feature:\n",
        "    all_data['mix_ind'] = all_data[ind_feature].astype(str) + \"_\"\n",
        "    is_first_feature = False\n",
        "  else:\n",
        "    all_data['mix_ind'] += all_data[ind_feature].astype(str) + \"_\""
      ],
      "metadata": {
        "id": "rfGDW89Y3hXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data['mix_ind']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "JZt6ar6X1C2e",
        "outputId": "8f555a8f-3b65-4fd0-e7bf-96345a20f901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n",
              "1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n",
              "2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n",
              "3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n",
              "4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n",
              "                           ...                  \n",
              "1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n",
              "1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n",
              "1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n",
              "1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n",
              "1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\n",
              "Name: mix_ind, Length: 1488028, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mix_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488023</th>\n",
              "      <td>0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488024</th>\n",
              "      <td>5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488025</th>\n",
              "      <td>0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488026</th>\n",
              "      <td>6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488027</th>\n",
              "      <td>7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1488028 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* categorical features"
      ],
      "metadata": {
        "id": "22_JhwSe423N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_count_features = []\n",
        "\n",
        "for feature in cat_features + ['mix_ind']:\n",
        "  value_counts_dict = all_data[feature].value_counts().to_dict()\n",
        "  all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: value_counts_dict[x])\n",
        "\n",
        "  cat_count_features.append(f'{feature}_count')"
      ],
      "metadata": {
        "id": "vyorAE0u45Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_count_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsjtWwUgxqHR",
        "outputId": "a0e000f6-40ff-416e-c185-149c3c18b8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ps_ind_02_cat_count',\n",
              " 'ps_ind_04_cat_count',\n",
              " 'ps_ind_05_cat_count',\n",
              " 'ps_car_01_cat_count',\n",
              " 'ps_car_02_cat_count',\n",
              " 'ps_car_03_cat_count',\n",
              " 'ps_car_04_cat_count',\n",
              " 'ps_car_05_cat_count',\n",
              " 'ps_car_06_cat_count',\n",
              " 'ps_car_07_cat_count',\n",
              " 'ps_car_08_cat_count',\n",
              " 'ps_car_09_cat_count',\n",
              " 'ps_car_10_cat_count',\n",
              " 'ps_car_11_cat_count',\n",
              " 'mix_ind_count']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove unnecessary features"
      ],
      "metadata": {
        "id": "mas8HK0-6VMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "drop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n",
        "\n",
        "# After dropping feature\n",
        "all_data_remaining = all_data[remaining_features + cat_count_features].drop(drop_features, axis = 1)"
      ],
      "metadata": {
        "id": "x2mLMjbW6f5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining), encoded_cat_matrix], format='csr')"
      ],
      "metadata": {
        "id": "vI8RNgPL7JqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_sprs.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3iiRcQ97fv2",
        "outputId": "8ec9700d-d23c-46fd-cbb3-05d1f81c087e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 5., 1., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Split"
      ],
      "metadata": {
        "id": "6QnDic_T7vM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = len(train)   # the number of train data\n",
        "X = all_data_sprs[:num_train]\n",
        "X_test = all_data_sprs[num_train:]\n",
        "y = train['target'].values"
      ],
      "metadata": {
        "id": "WucfvGcO7w8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalized Gini coefficient calculation function"
      ],
      "metadata": {
        "id": "6Meexqbs8Rj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def eval_gini(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  return the normalized coefficient given an actual target vaues and a predicted probability value\n",
        "  \"\"\"\n",
        "  #Check if the actual and predicted values are the same size\n",
        "  assert y_true.shape == y_pred.shape\n",
        "\n",
        "  n_samples = y_true.shape[0]   # data count\n",
        "\n",
        "  #start : The starting vlaues of the sequence\n",
        "  #stop  : The ending values of the sequence\n",
        "  #num   : Number of samples to generate. Default is 50, must be non-negative\n",
        "  L_mid = np.linspace(start = 1/ n_samples,  stop = 1, num=n_samples)  # 대각선값\n",
        "\n",
        "  #1) Gini coefficient for the predicted values : Gini coefficient obtained by taking the predicted and actual value\n",
        "  pred_order = y_true[y_pred.argsort()]  # Sort the actual values by the magnitude of the predicted values\n",
        "  L_pred     = np.cumsum(pred_order) / np.sum(pred_order)  # Lorenz curve\n",
        "  G_pred     = np.sum(L_mid - L_pred)    #Gini coefficeint when the prediction is perfect\n",
        "\n",
        "  #2) Gini coefficient where the prediction is perfect - 예측이 완벽할때의 지니계수 - 실제값과 실제값으로 구한 지니계수\n",
        "  true_order = y_true[y_true.argsort()]  # Sort the actual value by the magnitude of the actual value\n",
        "  L_true     = np.cumsum(true_order) / np.sum(true_order)\n",
        "  G_true     = np.sum(L_mid - L_true)\n",
        "\n",
        "  #nomalized gini coefficent\n",
        "  return G_pred / G_true\n",
        "\n"
      ],
      "metadata": {
        "id": "3r2_roDj8YsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* XGBoost gini function"
      ],
      "metadata": {
        "id": "A6xgtg2oANad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_gini(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  return 'gini', eval_gini(labels, preds)"
      ],
      "metadata": {
        "id": "hCKgQZWBARDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* LightGBM gini function"
      ],
      "metadata": {
        "id": "_t15QtUfA2N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lightgbm_gini(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  return 'gini', eval_gini(labels, preds), True"
      ],
      "metadata": {
        "id": "tc40ToStAkvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "4d_NOZcQBCId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset prepation"
      ],
      "metadata": {
        "id": "sVRwZJTbBHLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "mTShPDZ8BKwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate training and validation data with an 8:2 ratio\n",
        "X_train, X_valid, y_train, y_valid  = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
        "\n",
        "#Bayessian Optimization Dataset\n",
        "bayes_dtrain = xgb.DMatrix(X_train, y_train)\n",
        "bayes_dvalid = xgb.DMatrix(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "GdJyQ4k0BSem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter boundary set"
      ],
      "metadata": {
        "id": "h8qoWUGsB-u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_bounds = {\n",
        "                'max_depth':(4,8),\n",
        "                'subsample': (0.6, 0.9),\n",
        "                'colsample_bytree':(0.7, 1.0),\n",
        "                'min_child_weight': (5,7),\n",
        "                'gamma': (8, 11),\n",
        "                'reg_alpah':(7, 9),\n",
        "                'reg_lambda':(1.1, 1.5),\n",
        "                'scale_pos_weight':(1.4, 1.6)\n",
        "}\n",
        "#Fixed Hyperparameter\n",
        "fixed_params = {\n",
        "              'objective':'binary:logistic',\n",
        "              'learning_rate':0.02,\n",
        "              'random_state': 1991\n",
        "}\n"
      ],
      "metadata": {
        "id": "71rmxiXZCCml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics Calculation Function(Bayesian Optimization)"
      ],
      "metadata": {
        "id": "YyU-QgsyDLB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_function(max_depth,\n",
        "                  subsample,\n",
        "                  colsample_bytree,\n",
        "                  min_child_weight,\n",
        "                  reg_alpah,\n",
        "                  gamma,\n",
        "                  reg_lambda,\n",
        "                  scale_pos_weight):\n",
        "  '''\n",
        "  1) Hyperparameter for Bayesian Optimization\n",
        "  '''\n",
        "  params = {\n",
        "        'max_depth': int(round(max_depth)),\n",
        "        'subsample': subsample,\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'min_child_weight': min_child_weight,\n",
        "        'gamma': gamma,\n",
        "        'reg_alpha': reg_alpah,\n",
        "        'reg_lambda': reg_lambda,\n",
        "        'scale_pos_weight':scale_pos_weight\n",
        "  }\n",
        "\n",
        "  #2) Add fixd hyperparameter\n",
        "  params.update(fixed_params)\n",
        "  print('Hyper parameter : ', params)\n",
        "\n",
        "  #3)XGBoost model train\n",
        "  xgb_model = xgb.train(params = params,\n",
        "                        dtrain = bayes_dtrain,\n",
        "                        num_boost_round =2000,\n",
        "                        evals = [(bayes_dvalid, 'bayes_dvalid')], #4) evals - parameters to pass validation data\n",
        "                        maximize=True,   #True means the larger gini coefficient for evaluation, the better\n",
        "                        feval = xgb_gini,\n",
        "                        early_stopping_rounds = 200,\n",
        "                        verbose_eval = False\n",
        "                        )\n",
        "\n",
        "  best_iter = xgb_model.best_iteration  # Number of boosting iteration for best parameter\n",
        "\n",
        "  #) XGBoost model requires a dataset in the form of a DMatrix for prediction\n",
        "  preds = xgb_model.predict(bayes_dvalid, iteration_range=(0, best_iter))\n",
        "\n",
        "  #Gini coefficient\n",
        "  gini_score = eval_gini(y_valid, preds)\n",
        "  print(f'Gini Coefficient : {gini_score}\\n')\n",
        "  return gini_score\n"
      ],
      "metadata": {
        "id": "EsrFLqqbDRKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   `evals` parameter - parameters to pass validation data\n",
        "    Note) If you want to use both training data and validation, you can use the following e,g) [(bayes_dtrain, 'bayes_dtrain'), (bayes_dvalid,'bayes_dvalid')]\n",
        "\n",
        "*   `maximize` parameter : True means the larger gini coefficients for evaluation, the better\n",
        "\n",
        "\n",
        "*   `num_boost_round` : The number of boosting iterations for best performance\n",
        "*   `predict` method requires a dataset in the form of a DMatrix for prediction\n",
        "\n",
        "\n",
        "*   `iteration_range` : The XGBoosing model requires the number of boosting iteration\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uJ8cbObkJa3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization Process"
      ],
      "metadata": {
        "id": "4-v8jXe3Kxnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "optimizer = BayesianOptimization(f=eval_function, pbounds=param_bounds, random_state=0)\n",
        "\n",
        "# Process\n",
        "optimizer.maximize(init_points=3, #Number of random points to probe before starting the optimization\n",
        "                   n_iter = 6  #Number of iterations where the method attempts to find the maximum value\n",
        "                   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95M3Q8xBK1wt",
        "outputId": "e2c1ac64-d926-460c-ac39-48740015a6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpah | reg_la... | scale_... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n",
            "Hyper parameter :  {'max_depth': 6, 'subsample': np.float64(0.867531900234624), 'colsample_bytree': np.float64(0.8646440511781974), 'min_child_weight': np.float64(6.0897663659937935), 'gamma': np.float64(10.14556809911726), 'reg_alpha': np.float64(7.84730959867781), 'reg_lambda': np.float64(1.3583576452266626), 'scale_pos_weight': np.float64(1.4875174422525386), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n",
            "Gini Coefficient : 0.2773061412072889\n",
            "\n",
            "| \u001b[39m1        \u001b[39m | \u001b[39m0.2773   \u001b[39m | \u001b[39m0.8646   \u001b[39m | \u001b[39m10.15    \u001b[39m | \u001b[39m6.411    \u001b[39m | \u001b[39m6.09     \u001b[39m | \u001b[39m7.847    \u001b[39m | \u001b[39m1.358    \u001b[39m | \u001b[39m1.488    \u001b[39m | \u001b[39m0.8675   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 7, 'subsample': np.float64(0.6261387899104622), 'colsample_bytree': np.float64(0.9890988281503088), 'min_child_weight': np.float64(6.0577898395058085), 'gamma': np.float64(9.150324556477333), 'reg_alpha': np.float64(8.136089122187865), 'reg_lambda': np.float64(1.4702386553170643), 'scale_pos_weight': np.float64(1.4142072116395774), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n",
            "Gini Coefficient : 0.27931481612089537\n",
            "\n",
            "| \u001b[35m2        \u001b[39m | \u001b[35m0.2793   \u001b[39m | \u001b[35m0.9891   \u001b[39m | \u001b[35m9.15     \u001b[39m | \u001b[35m7.167    \u001b[39m | \u001b[35m6.058    \u001b[39m | \u001b[35m8.136    \u001b[39m | \u001b[35m1.47     \u001b[39m | \u001b[35m1.414    \u001b[39m | \u001b[35m0.6261   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 7, 'subsample': np.float64(0.8341587528859367), 'colsample_bytree': np.float64(0.7060655192320977), 'min_child_weight': np.float64(6.7400242964936385), 'gamma': np.float64(10.497859536643814), 'reg_alpha': np.float64(8.957236684465528), 'reg_lambda': np.float64(1.4196634256866894), 'scale_pos_weight': np.float64(1.4922958724505864), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n",
            "Gini Coefficient : 0.2771016567222187\n",
            "\n",
            "| \u001b[39m3        \u001b[39m | \u001b[39m0.2771   \u001b[39m | \u001b[39m0.7061   \u001b[39m | \u001b[39m10.5     \u001b[39m | \u001b[39m7.113    \u001b[39m | \u001b[39m6.74     \u001b[39m | \u001b[39m8.957    \u001b[39m | \u001b[39m1.42     \u001b[39m | \u001b[39m1.492    \u001b[39m | \u001b[39m0.8342   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 7, 'subsample': np.float64(0.7001630536555632), 'colsample_bytree': np.float64(0.8843124587484356), 'min_child_weight': np.float64(6.494091293383359), 'gamma': np.float64(10.452246227672624), 'reg_alpha': np.float64(8.551838810159788), 'reg_lambda': np.float64(1.3814765995549108), 'scale_pos_weight': np.float64(1.423280772455086), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Coefficient : 0.27712980012771776\n",
            "\n",
            "| \u001b[39m4        \u001b[39m | \u001b[39m0.2771   \u001b[39m | \u001b[39m0.8843   \u001b[39m | \u001b[39m10.45    \u001b[39m | \u001b[39m6.838    \u001b[39m | \u001b[39m6.494    \u001b[39m | \u001b[39m8.552    \u001b[39m | \u001b[39m1.381    \u001b[39m | \u001b[39m1.423    \u001b[39m | \u001b[39m0.7002   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 7, 'subsample': np.float64(0.626187069353896), 'colsample_bytree': np.float64(0.9449714578668682), 'min_child_weight': np.float64(5.809125328782874), 'gamma': np.float64(8.534505859301504), 'reg_alpha': np.float64(7.766737728077027), 'reg_lambda': np.float64(1.4718237465701323), 'scale_pos_weight': np.float64(1.466192258700142), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Coefficient : 0.28031218444560413\n",
            "\n",
            "| \u001b[35m5        \u001b[39m | \u001b[35m0.2803   \u001b[39m | \u001b[35m0.945    \u001b[39m | \u001b[35m8.535    \u001b[39m | \u001b[35m7.343    \u001b[39m | \u001b[35m5.809    \u001b[39m | \u001b[35m7.767    \u001b[39m | \u001b[35m1.472    \u001b[39m | \u001b[35m1.466    \u001b[39m | \u001b[35m0.6262   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 8, 'subsample': np.float64(0.8590535247766051), 'colsample_bytree': np.float64(0.9393951223603955), 'min_child_weight': np.float64(5.157710468794807), 'gamma': np.float64(8.006603748128352), 'reg_alpha': np.float64(8.986014657276067), 'reg_lambda': np.float64(1.1983263550512122), 'scale_pos_weight': np.float64(1.4637406456268638), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Coefficient : 0.2795728296867123\n",
            "\n",
            "| \u001b[39m6        \u001b[39m | \u001b[39m0.2796   \u001b[39m | \u001b[39m0.9394   \u001b[39m | \u001b[39m8.007    \u001b[39m | \u001b[39m7.951    \u001b[39m | \u001b[39m5.158    \u001b[39m | \u001b[39m8.986    \u001b[39m | \u001b[39m1.198    \u001b[39m | \u001b[39m1.464    \u001b[39m | \u001b[39m0.8591   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 8, 'subsample': np.float64(0.8334108180613197), 'colsample_bytree': np.float64(0.9766323758595331), 'min_child_weight': np.float64(6.982277450365352), 'gamma': np.float64(8.07546326379483), 'reg_alpha': np.float64(7.095081885792477), 'reg_lambda': np.float64(1.12770911691504), 'scale_pos_weight': np.float64(1.5175625550380736), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Coefficient : 0.2801592193756867\n",
            "\n",
            "| \u001b[39m7        \u001b[39m | \u001b[39m0.2802   \u001b[39m | \u001b[39m0.9766   \u001b[39m | \u001b[39m8.075    \u001b[39m | \u001b[39m7.895    \u001b[39m | \u001b[39m6.982    \u001b[39m | \u001b[39m7.095    \u001b[39m | \u001b[39m1.128    \u001b[39m | \u001b[39m1.518    \u001b[39m | \u001b[39m0.8334   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 8, 'subsample': np.float64(0.6633912108966), 'colsample_bytree': np.float64(0.975866107013157), 'min_child_weight': np.float64(5.007145412499934), 'gamma': np.float64(8.049322250846364), 'reg_alpha': np.float64(7.003236228101047), 'reg_lambda': np.float64(1.2420052039873415), 'scale_pos_weight': np.float64(1.454907620666363), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Coefficient : 0.2796224405260899\n",
            "\n",
            "| \u001b[39m8        \u001b[39m | \u001b[39m0.2796   \u001b[39m | \u001b[39m0.9759   \u001b[39m | \u001b[39m8.049    \u001b[39m | \u001b[39m7.803    \u001b[39m | \u001b[39m5.007    \u001b[39m | \u001b[39m7.003    \u001b[39m | \u001b[39m1.242    \u001b[39m | \u001b[39m1.455    \u001b[39m | \u001b[39m0.6634   \u001b[39m |\n",
            "Hyper parameter :  {'max_depth': 6, 'subsample': np.float64(0.6536907052227791), 'colsample_bytree': np.float64(0.8201640448429227), 'min_child_weight': np.float64(6.885405012451871), 'gamma': np.float64(8.012673139551556), 'reg_alpha': np.float64(8.22126905438746), 'reg_lambda': np.float64(1.3082690271128425), 'scale_pos_weight': np.float64(1.504242833500432), 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Coefficient : 0.2811377283838368\n",
            "\n",
            "| \u001b[35m9        \u001b[39m | \u001b[35m0.2811   \u001b[39m | \u001b[35m0.8202   \u001b[39m | \u001b[35m8.013    \u001b[39m | \u001b[35m6.199    \u001b[39m | \u001b[35m6.885    \u001b[39m | \u001b[35m8.221    \u001b[39m | \u001b[35m1.308    \u001b[39m | \u001b[35m1.504    \u001b[39m | \u001b[35m0.6537   \u001b[39m |\n",
            "=========================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result Confirm"
      ],
      "metadata": {
        "id": "_VakM_gnNkIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter where the evaluation score is maximized\n",
        "max_params = optimizer.max['params']\n",
        "max_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6vfsm-yB8jM",
        "outputId": "bf3c6f86-d69e-4dbe-af90-60c78a4a6b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colsample_bytree': np.float64(0.8201640448429227),\n",
              " 'gamma': np.float64(8.012673139551556),\n",
              " 'max_depth': np.float64(6.1990139748822735),\n",
              " 'min_child_weight': np.float64(6.885405012451871),\n",
              " 'reg_alpah': np.float64(8.22126905438746),\n",
              " 'reg_lambda': np.float64(1.3082690271128425),\n",
              " 'scale_pos_weight': np.float64(1.504242833500432),\n",
              " 'subsample': np.float64(0.6536907052227791)}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert int type\n",
        "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
        "max_params.update(fixed_params)"
      ],
      "metadata": {
        "id": "HET_dWRhBv9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Train with the best hyperparameter and Evaluation Performance"
      ],
      "metadata": {
        "id": "vspOVuqkOb5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#Cross-Validation using StratifiedKFold\n",
        "folds = StratifiedKFold(n_splits = 5,  #Number of folds, Must be at least 2\n",
        "                        shuffle=True,\n",
        "                        random_state = 1991)\n",
        "\n",
        "#A one-dimensional array to hold the probability that the model trained with the OOF method predicted the target value of the validation data\n",
        "oof_val_preds = np.zeros(X.shape[0])\n",
        "\n",
        "#A one-dimensional array to hold the probability that the model trained with the OOF method predicted the target value of the test data\n",
        "oof_test_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "  print('#' * 40, f'Folds {idx + 1} / Fold (folds.n_splits)', '#' * 40)\n",
        "\n",
        "  #Data for train and validation\n",
        "  X_train, y_train = X[train_idx], y[train_idx]\n",
        "  X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
        "\n",
        "  #Dedicated Dataset for XGBoost\n",
        "  dtrain = xgb.DMatrix(X_train, y_train)\n",
        "  dvalid = xgb.DMatrix(X_valid, y_valid)\n",
        "  dtest  = xgb.DMatrix(X_test)\n",
        "\n",
        "  #XGBoost Model train\n",
        "  xgb_model = xgb.train(\n",
        "                      params = max_params,\n",
        "                      dtrain = dtrain,\n",
        "                      num_boost_round = 2000,\n",
        "                      evals  = [(dvalid, 'valid')],\n",
        "                      maximize = True,\n",
        "                      feval  = xgb_gini,\n",
        "                      early_stopping_rounds = 200,\n",
        "                      verbose_eval = 100\n",
        "  )\n",
        "\n",
        "  #Store the number of boosting iterations where the model perfoms best\n",
        "  best_iter = xgb_model.best_iteration\n",
        "\n",
        "  # OOF Prediction with the test data\n",
        "  oof_test_preds += xgb_model.predict(dtest,\n",
        "                                       iteration_range=(0, best_iter)) / folds.n_splits\n",
        "\n",
        "  # Predict target values in validation data for model evaluation\n",
        "  oof_val_preds[valid_idx] = xgb_model.predict(dvalid, iteration_range=(0, best_iter))\n",
        "\n",
        "  #Normalized Gini coefficient for the preditive probability of the validation data\n",
        "  gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
        "  print(f'Fold {idx + 1}  Gini Coefficient : {gini_score} \\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLxcMdt5PS_Q",
        "outputId": "4f7b889f-8635-4d3e-b322-4c1f262dbabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######################################## Folds 1 / Fold (folds.n_splits) ########################################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:52:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"reg_alpah\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalid-logloss:0.21860\tvalid-gini:0.21934\n",
            "[100]\tvalid-logloss:0.16093\tvalid-gini:0.27658\n",
            "[200]\tvalid-logloss:0.15566\tvalid-gini:0.28756\n",
            "[300]\tvalid-logloss:0.15493\tvalid-gini:0.29255\n",
            "[400]\tvalid-logloss:0.15481\tvalid-gini:0.29455\n",
            "[500]\tvalid-logloss:0.15476\tvalid-gini:0.29518\n",
            "[600]\tvalid-logloss:0.15474\tvalid-gini:0.29540\n",
            "[700]\tvalid-logloss:0.15474\tvalid-gini:0.29541\n",
            "[800]\tvalid-logloss:0.15473\tvalid-gini:0.29560\n",
            "[900]\tvalid-logloss:0.15476\tvalid-gini:0.29545\n",
            "[965]\tvalid-logloss:0.15473\tvalid-gini:0.29544\n",
            "Fold 1  Gini Coefficient : 0.29572391803317216 \n",
            "\n",
            "######################################## Folds 2 / Fold (folds.n_splits) ########################################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:54:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"reg_alpah\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalid-logloss:0.21860\tvalid-gini:0.20456\n",
            "[100]\tvalid-logloss:0.16115\tvalid-gini:0.26348\n",
            "[200]\tvalid-logloss:0.15601\tvalid-gini:0.27332\n",
            "[300]\tvalid-logloss:0.15532\tvalid-gini:0.27785\n",
            "[400]\tvalid-logloss:0.15522\tvalid-gini:0.27937\n",
            "[500]\tvalid-logloss:0.15519\tvalid-gini:0.27974\n",
            "[600]\tvalid-logloss:0.15519\tvalid-gini:0.28000\n",
            "[700]\tvalid-logloss:0.15517\tvalid-gini:0.28042\n",
            "[800]\tvalid-logloss:0.15516\tvalid-gini:0.28092\n",
            "[900]\tvalid-logloss:0.15517\tvalid-gini:0.28108\n",
            "[1000]\tvalid-logloss:0.15514\tvalid-gini:0.28118\n",
            "[1100]\tvalid-logloss:0.15512\tvalid-gini:0.28137\n",
            "[1200]\tvalid-logloss:0.15512\tvalid-gini:0.28148\n",
            "[1300]\tvalid-logloss:0.15514\tvalid-gini:0.28148\n",
            "[1400]\tvalid-logloss:0.15513\tvalid-gini:0.28183\n",
            "[1500]\tvalid-logloss:0.15513\tvalid-gini:0.28183\n",
            "[1600]\tvalid-logloss:0.15512\tvalid-gini:0.28179\n",
            "[1700]\tvalid-logloss:0.15512\tvalid-gini:0.28198\n",
            "[1800]\tvalid-logloss:0.15511\tvalid-gini:0.28210\n",
            "[1900]\tvalid-logloss:0.15510\tvalid-gini:0.28218\n",
            "[1999]\tvalid-logloss:0.15510\tvalid-gini:0.28223\n",
            "Fold 2  Gini Coefficient : 0.2822101604784705 \n",
            "\n",
            "######################################## Folds 3 / Fold (folds.n_splits) ########################################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:58:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"reg_alpah\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalid-logloss:0.21860\tvalid-gini:0.22080\n",
            "[100]\tvalid-logloss:0.16094\tvalid-gini:0.26906\n",
            "[200]\tvalid-logloss:0.15567\tvalid-gini:0.27979\n",
            "[300]\tvalid-logloss:0.15497\tvalid-gini:0.28374\n",
            "[400]\tvalid-logloss:0.15487\tvalid-gini:0.28436\n",
            "[500]\tvalid-logloss:0.15483\tvalid-gini:0.28451\n",
            "[600]\tvalid-logloss:0.15482\tvalid-gini:0.28465\n",
            "[700]\tvalid-logloss:0.15480\tvalid-gini:0.28478\n",
            "[800]\tvalid-logloss:0.15484\tvalid-gini:0.28443\n",
            "[863]\tvalid-logloss:0.15483\tvalid-gini:0.28437\n",
            "Fold 3  Gini Coefficient : 0.28492281470197145 \n",
            "\n",
            "######################################## Folds 4 / Fold (folds.n_splits) ########################################\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:00:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"reg_alpah\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalid-logloss:0.21860\tvalid-gini:0.21735\n",
            "[100]\tvalid-logloss:0.16103\tvalid-gini:0.26165\n",
            "[200]\tvalid-logloss:0.15590\tvalid-gini:0.27159\n",
            "[300]\tvalid-logloss:0.15525\tvalid-gini:0.27469\n",
            "[400]\tvalid-logloss:0.15514\tvalid-gini:0.27570\n",
            "[500]\tvalid-logloss:0.15512\tvalid-gini:0.27620\n",
            "[600]\tvalid-logloss:0.15510\tvalid-gini:0.27653\n",
            "[700]\tvalid-logloss:0.15510\tvalid-gini:0.27690\n",
            "[800]\tvalid-logloss:0.15512\tvalid-gini:0.27681\n",
            "[900]\tvalid-logloss:0.15511\tvalid-gini:0.27686\n",
            "[1000]\tvalid-logloss:0.15509\tvalid-gini:0.27684\n",
            "[1026]\tvalid-logloss:0.15510\tvalid-gini:0.27677\n",
            "Fold 4  Gini Coefficient : 0.2768652816854179 \n",
            "\n",
            "######################################## Folds 5 / Fold (folds.n_splits) ########################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:02:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"reg_alpah\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalid-logloss:0.21861\tvalid-gini:0.20994\n",
            "[100]\tvalid-logloss:0.16114\tvalid-gini:0.27266\n",
            "[200]\tvalid-logloss:0.15595\tvalid-gini:0.28267\n",
            "[300]\tvalid-logloss:0.15528\tvalid-gini:0.28646\n",
            "[400]\tvalid-logloss:0.15518\tvalid-gini:0.28761\n",
            "[500]\tvalid-logloss:0.15513\tvalid-gini:0.28826\n",
            "[600]\tvalid-logloss:0.15510\tvalid-gini:0.28868\n",
            "[700]\tvalid-logloss:0.15508\tvalid-gini:0.28925\n",
            "[800]\tvalid-logloss:0.15508\tvalid-gini:0.28956\n",
            "[900]\tvalid-logloss:0.15506\tvalid-gini:0.28982\n",
            "[1000]\tvalid-logloss:0.15507\tvalid-gini:0.28992\n",
            "[1100]\tvalid-logloss:0.15506\tvalid-gini:0.29015\n",
            "[1200]\tvalid-logloss:0.15506\tvalid-gini:0.29031\n",
            "[1300]\tvalid-logloss:0.15503\tvalid-gini:0.29049\n",
            "[1400]\tvalid-logloss:0.15505\tvalid-gini:0.29059\n",
            "[1500]\tvalid-logloss:0.15504\tvalid-gini:0.29055\n",
            "[1600]\tvalid-logloss:0.15505\tvalid-gini:0.29093\n",
            "[1700]\tvalid-logloss:0.15502\tvalid-gini:0.29093\n",
            "[1800]\tvalid-logloss:0.15503\tvalid-gini:0.29089\n",
            "[1900]\tvalid-logloss:0.15502\tvalid-gini:0.29096\n",
            "[1999]\tvalid-logloss:0.15502\tvalid-gini:0.29089\n",
            "Fold 5  Gini Coefficient : 0.2909378230339609 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'OOF Validation Data Gini Coefficient : ', {eval_gini(y, oof_val_preds)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neOs1NhOULN-",
        "outputId": "666ba8aa-48ac-44ca-efc1-6f6db7524574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF Validation Data Gini Coefficient :  {np.float64(0.28601005274862423)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit Result"
      ],
      "metadata": {
        "id": "QNqXmv8LUM1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission['target'] = oof_test_preds\n",
        "submission.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "AxxJ4-hjBGjh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}